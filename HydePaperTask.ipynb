{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import some things\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "import astropy.coordinates as coord\n",
        "import astropy.units as u\n",
        "from astropy.io import fits, ascii\n",
        "from astropy.table import Table\n",
        "from astropy.coordinates import SkyCoord"
      ],
      "metadata": {
        "id": "MEGrfsKxpeJg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load in the data (may have to change this for wherever you downloaded your file)\n",
        "#in google colab you can get the file using\n",
        "#!wget https://dr19.sdss.org/sas/dr19/spectro/astra/0.6.0/summary/astraAllStarASPCAP-0.6.0.fits.gz\n",
        "\n",
        "filename='astraAllStarASPCAP-0.6.0.fits.gz'\n",
        "tb = fits.open(filename)\n",
        "header=tb[2].header\n",
        "data = tb[2].data"
      ],
      "metadata": {
        "id": "cXQ8eauEp0RH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_gaia = (data['zgr_plx']>0)\n"
      ],
      "metadata": {
        "id": "zl5DH92Gp5zj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_masked=data[mask_gaia]"
      ],
      "metadata": {
        "id": "gXCgVzRYqljA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Age option 1 TESS data Theodoridis et al. 2025\n",
        "#Reading in the table, making sure all the tables have a column named Age in Gyr\n",
        "# and that every star in the table has an Age\n",
        "tessraw = Table.read(\"Theodoridis2025 (1).csv\", format=\"ascii\")\n",
        "#this one has an age column in Gyr already so we're just going to rename it Age\n",
        "tessraw['Final_age'].name='Age'\n",
        "hasagetess=np.where((tessraw['Age']==tessraw['Age']) & (tessraw['Age']>0.1) &(tessraw['Flag']==0))\n",
        "tess=tessraw[hasagetess]\n",
        "tess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "lJrtf37NpTBP",
        "outputId": "dff2ead3-a865-42f2-9af2-d0d65c04e449"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Table length=124340>\n",
              "   TIC    Star_type        Age         ...      Teff_diff       Flag\n",
              "  int64      str5        float64       ...       float64       int64\n",
              "--------- --------- ------------------ ... ------------------- -----\n",
              "347020604     Clump  4.933697638292032 ...  174.04556888801108     0\n",
              "365250045       RGB  5.919390103924665 ...   97.59468645767902     0\n",
              "377058143       RGB 10.659761236332615 ...  -113.8047440968976     0\n",
              "347548024       RGB 4.2433496208314345 ...  -141.2146776884456     0\n",
              "328321210     Clump  5.297976079237009 ...   219.9442341489521     0\n",
              "328321103       RGB   3.76901613056093 ...  -49.01280965939077     0\n",
              "328324062     Clump  2.303632505100647 ...    224.565928540389     0\n",
              "328400618     Clump  2.159728298323744 ...  132.08513858645256     0\n",
              "328255103     Clump  6.418514994888695 ...  199.00344572811537     0\n",
              "      ...       ...                ... ...                 ...   ...\n",
              " 24293754     Clump  7.270499767640112 ...   100.7095877557831     0\n",
              "444151014       RGB 1.3293989221533338 ...    5.87378596065173     0\n",
              "439387397       RGB 10.886531443589943 ... -19.501883450057903     0\n",
              "439387373       RGB 13.559665913368113 ...  -82.24621400531942     0\n",
              "415686794     Clump 3.5268592139224655 ...  265.21086792035476     0\n",
              " 99837810     Clump 11.042183147979149 ...  174.07698216540484     0\n",
              " 99821552       RGB 2.1627981000040437 ... -109.79588133983816     0\n",
              "441029961     Clump  4.068854769155727 ...  118.59480020653608     0\n",
              "441015317       RGB        10.13177954 ...  -18.31305666275875     0\n",
              " 99818843       RGB  6.006672813122813 ... -155.28605255012826     0"
            ],
            "text/html": [
              "<div><i>Table length=124340</i>\n",
              "<table id=\"table137769578282448\" class=\"table-striped table-bordered table-condensed\">\n",
              "<thead><tr><th>TIC</th><th>Star_type</th><th>Age</th><th>νmax</th><th>Radius_gaia</th><th>Teff_xgboost</th><th>M_H_xgboost</th><th>Logg_xgboost</th><th>Logg_seis</th><th>E_Logg_seis</th><th>Mass_seis</th><th>E_Mass_seis</th><th>Initial_mass</th><th>Teff_rgb</th><th>Teff_rc</th><th>Median_age_rgb</th><th>Median_age_rc</th><th>E_lower_age_rgb</th><th>E_upper_age_rgb</th><th>E_lower_age_rc</th><th>E_upper_age_rc</th><th>Teff_diff</th><th>Flag</th></tr></thead>\n",
              "<thead><tr><th>int64</th><th>str5</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th></tr></thead>\n",
              "<tr><td>347020604</td><td>Clump</td><td>4.933697638292032</td><td>32.2</td><td>10.8</td><td>4766.6</td><td>-0.161</td><td>2.432</td><td>2.4173752480453827</td><td>0.0366707608673319</td><td>1.1120077414967078</td><td>0.0588614326241161</td><td>1.2303580537284051</td><td>4573.560449427352</td><td>4592.554431111989</td><td>7.362373244</td><td>4.928036510093708</td><td>6.081092717</td><td>8.892029592</td><td>4.299934128259921</td><td>6.1356166056543815</td><td>174.04556888801108</td><td>0</td></tr>\n",
              "<tr><td>365250045</td><td>RGB</td><td>5.919390103924665</td><td>33.0</td><td>10.8</td><td>4931.7</td><td>-0.342</td><td>2.455</td><td>2.4229857865111493</td><td>0.0357953759646522</td><td>1.126466677413624</td><td>0.056320640605</td><td>1.1264672739859862</td><td>4667.980210870163</td><td>4834.105313542321</td><td>5.948811656</td><td>4.27541564590489</td><td>5.120775603</td><td>7.010332121</td><td>3.7125897559954217</td><td>4.990341868284544</td><td>97.59468645767902</td><td>0</td></tr>\n",
              "<tr><td>377058143</td><td>RGB</td><td>10.659761236332615</td><td>59.1</td><td>7.3</td><td>4732.1</td><td>-0.519</td><td>2.615</td><td>2.677206425366256</td><td>0.0648094481080465</td><td>0.9241388003056158</td><td>0.0471439463924816</td><td>0.9241384053448526</td><td>4809.243666602538</td><td>4845.904744096898</td><td>11.11556225</td><td>5.653288060595535</td><td>9.53022434</td><td>12.72313934</td><td>4.950738403099905</td><td>6.798479977799735</td><td>-113.8047440968976</td><td>0</td></tr>\n",
              "<tr><td>347548024</td><td>RGB</td><td>4.2433496208314345</td><td>33.2</td><td>11.5</td><td>4634.4</td><td>-0.213</td><td>2.388</td><td>2.4218043131513705</td><td>0.0720751969086103</td><td>1.2737524436569616</td><td>0.0852469599851652</td><td>1.2737527853903323</td><td>4625.72134164397</td><td>4775.614677688445</td><td>4.196919598</td><td>3.1842561951173276</td><td>3.279495422</td><td>5.737266629</td><td>2.7003724708906987</td><td>3.926199760609352</td><td>-141.2146776884456</td><td>0</td></tr>\n",
              "<tr><td>328321210</td><td>Clump</td><td>5.297976079237009</td><td>35.7</td><td>9.6</td><td>4982.0</td><td>-0.526</td><td>2.441</td><td>2.4671643779400427</td><td>0.0755464565388593</td><td>0.9853531626679212</td><td>0.0677079590734425</td><td>1.121116190405825</td><td>4737.2709053692715</td><td>4762.055765851048</td><td>9.131354832</td><td>5.481214180765681</td><td>6.619391066</td><td>11.17929356</td><td>4.57496878200937</td><td>6.826530999798273</td><td>219.9442341489521</td><td>0</td></tr>\n",
              "<tr><td>328321103</td><td>RGB</td><td>3.76901613056093</td><td>34.5</td><td>11.4</td><td>4765.0</td><td>-0.277</td><td>2.533</td><td>2.438719284222579</td><td>0.0355087401732596</td><td>1.3014095644450476</td><td>0.0659512559797257</td><td>1.301409615256684</td><td>4669.883118807332</td><td>4814.012809659391</td><td>3.7183394</td><td>2.964010779639734</td><td>3.222621332</td><td>4.398228001</td><td>2.51085645776994</td><td>3.520642797490074</td><td>-49.01280965939077</td><td>0</td></tr>\n",
              "<tr><td>328324062</td><td>Clump</td><td>2.303632505100647</td><td>41.3</td><td>11.3</td><td>4792.0</td><td>0.085</td><td>2.617</td><td>2.5205598637381987</td><td>0.0266418863144747</td><td>1.5438382675435354</td><td>0.0669944467135548</td><td>1.6114631436790468</td><td>4552.67752843955</td><td>4567.434071459611</td><td>2.700422808</td><td>2.2357112051063632</td><td>2.255954628</td><td>3.155200636</td><td>1.9961451072036724</td><td>2.638300639580447</td><td>224.565928540389</td><td>0</td></tr>\n",
              "<tr><td>328400618</td><td>Clump</td><td>2.159728298323744</td><td>44.1</td><td>10.5</td><td>4910.2</td><td>-0.319</td><td>2.472</td><td>2.557435937807216</td><td>0.0739867137774788</td><td>1.4511074516675977</td><td>0.0926043469167527</td><td>1.5165343396975142</td><td>4767.690838544538</td><td>4778.114861413547</td><td>2.561181642</td><td>2.157582282377099</td><td>2.082416797</td><td>3.109146383</td><td>1.7850147949917456</td><td>2.6517500725099072</td><td>132.08513858645256</td><td>0</td></tr>\n",
              "<tr><td>328255103</td><td>Clump</td><td>6.418514994888695</td><td>31.9</td><td>10.8</td><td>4686.6</td><td>0.019</td><td>2.433</td><td>2.406553604071016</td><td>0.0559847430029249</td><td>1.0846413740056715</td><td>0.0674371343640133</td><td>1.18744043140101</td><td>4471.252872082005</td><td>4487.596554271885</td><td>9.075683921</td><td>6.586728636664553</td><td>7.526636104</td><td>11.69375071</td><td>5.35273124007062</td><td>7.587960124712628</td><td>199.00344572811537</td><td>0</td></tr>\n",
              "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
              "<tr><td>24293754</td><td>Clump</td><td>7.270499767640112</td><td>30.9</td><td>10.2</td><td>4680.1</td><td>-0.2</td><td>2.428</td><td>2.399207980219463</td><td>0.0298296961867419</td><td>0.9512470957539596</td><td>0.0441236882134543</td><td>1.0956080340537082</td><td>4548.956849105674</td><td>4579.390412244217</td><td>12.42068752</td><td>7.310600524515545</td><td>10.69207048</td><td>15.40925913</td><td>6.310366637090926</td><td>8.712502028260396</td><td>100.7095877557831</td><td>0</td></tr>\n",
              "<tr><td>444151014</td><td>RGB</td><td>1.3293989221533338</td><td>42.0</td><td>12.7</td><td>4564.5</td><td>0.235</td><td>2.428</td><td>2.5241027057740677</td><td>0.0302942508281642</td><td>1.9660527727614991</td><td>0.1066372801170731</td><td>1.9660528317165893</td><td>4551.681217126331</td><td>4558.626214039348</td><td>1.337344976</td><td>1.2193055256945164</td><td>1.107826687</td><td>1.66771992</td><td>1.0892608398607586</td><td>1.455594566352458</td><td>5.87378596065173</td><td>0</td></tr>\n",
              "<tr><td>439387397</td><td>RGB</td><td>10.886531443589943</td><td>38.6</td><td>9.3</td><td>4631.1</td><td>-0.248</td><td>2.499</td><td>2.489396578020239</td><td>0.0508134259270761</td><td>0.9733018061196635</td><td>0.0521761267719925</td><td>0.9733012519116058</td><td>4620.716367755734</td><td>4650.601883450058</td><td>10.99454201</td><td>6.314006485124088</td><td>9.032860348</td><td>13.20527487</td><td>5.211545198833982</td><td>7.635994733477046</td><td>-19.501883450057903</td><td>0</td></tr>\n",
              "<tr><td>439387373</td><td>RGB</td><td>13.559665913368113</td><td>52.9</td><td>7.7</td><td>4598.5</td><td>-0.206</td><td>2.636</td><td>2.6307613177683287</td><td>0.0258131672540484</td><td>0.9239059902913592</td><td>0.0373936421046703</td><td>0.923906214083602</td><td>4641.654812571993</td><td>4680.746214005319</td><td>13.70737483</td><td>7.753563029049198</td><td>12.2628135</td><td>15.12569441</td><td>6.896534907227312</td><td>8.865732312274117</td><td>-82.24621400531942</td><td>0</td></tr>\n",
              "<tr><td>415686794</td><td>Clump</td><td>3.5268592139224655</td><td>37.9</td><td>10.9</td><td>4773.3</td><td>0.112</td><td>2.631</td><td>2.483340981191912</td><td>0.0267072980726848</td><td>1.3184965052627895</td><td>0.0575078402125955</td><td>1.4340694281462223</td><td>4488.851912716716</td><td>4508.089132079645</td><td>4.837948927</td><td>3.4995127765543605</td><td>4.256064234</td><td>5.586369343</td><td>2.954016975950612</td><td>4.00273702323879</td><td>265.21086792035476</td><td>0</td></tr>\n",
              "<tr><td>99837810</td><td>Clump</td><td>11.042183147979149</td><td>28.1</td><td>10.4</td><td>4605.9</td><td>0.016</td><td>2.431</td><td>2.3499336495620113</td><td>0.0712269930351832</td><td>0.8828467704108918</td><td>0.0635229717437992</td><td>1.0255068506336564</td><td>4399.246020147388</td><td>4431.823017834595</td><td>19.82332468</td><td>10.657076041429718</td><td>15.87245997</td><td>24.47288804</td><td>8.222377635684587</td><td>13.862395309695891</td><td>174.07698216540484</td><td>0</td></tr>\n",
              "<tr><td>99821552</td><td>RGB</td><td>2.1627981000040437</td><td>25.0</td><td>15.1</td><td>4420.4</td><td>-0.067</td><td>2.14</td><td>2.282880926371518</td><td>0.0817620341485557</td><td>1.5948501340660617</td><td>0.1271293994256553</td><td>1.5948499544670982</td><td>4521.13258638862</td><td>4530.195881339838</td><td>2.059770856</td><td>1.8605694698050377</td><td>1.656739446</td><td>2.680530158</td><td>1.4738695107846194</td><td>2.5179584189392616</td><td>-109.79588133983816</td><td>0</td></tr>\n",
              "<tr><td>441029961</td><td>Clump</td><td>4.068854769155727</td><td>35.5</td><td>10.6</td><td>4782.2</td><td>-0.251</td><td>2.454</td><td>2.4586662614356354</td><td>0.0272611630299921</td><td>1.1780481987255331</td><td>0.0525955456468396</td><td>1.279547727713048</td><td>4647.035647055904</td><td>4663.605199793464</td><td>5.528992072</td><td>3.875785579258347</td><td>4.639599327</td><td>6.24384432</td><td>3.4206135944114515</td><td>4.660127921049435</td><td>118.59480020653608</td><td>0</td></tr>\n",
              "<tr><td>441015317</td><td>RGB</td><td>10.13177954</td><td>25.4</td><td>12.1</td><td>4410.4</td><td>0.043</td><td>2.251</td><td>2.298070483513228</td><td>0.0446639679644</td><td>1.0605381308578825</td><td>0.0621831423234216</td><td>1.0605384566787168</td><td>4412.812108453358</td><td>4428.713056662758</td><td>10.11310758</td><td>7.127798454945256</td><td>8.257605623</td><td>12.28754288</td><td>5.930333252764051</td><td>8.430542558191812</td><td>-18.31305666275875</td><td>0</td></tr>\n",
              "<tr><td>99818843</td><td>RGB</td><td>6.006672813122813</td><td>30.3</td><td>11.4</td><td>4484.3</td><td>-0.292</td><td>2.301</td><td>2.37918647277568</td><td>0.0789505179281383</td><td>1.134700334062554</td><td>0.0825100846064691</td><td>1.1347006565422713</td><td>4621.617923416667</td><td>4639.586052550128</td><td>6.183338205</td><td>4.118140285608963</td><td>4.912764406</td><td>7.972203552</td><td>3.446298354171621</td><td>5.439509135147377</td><td>-155.28605255012826</td><td>0</td></tr>\n",
              "</table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Age option 3 APOKASC-3 Pinsonneault et al. 2025\n",
        "#Reading in the table, making sure all the tables have a column named Age in Gyr\n",
        "# and that every star in the table has an Age\n",
        "apokasc3raw= Table.read(\"Pinsonneault2025.txt\", format=\"ascii.cds\")\n",
        "#in this case there were two age columns, one for Red Clump and one for Red Giant Branch so we combine them\n",
        "ageRC=np.array(apokasc3raw['AgeRC']*(apokasc3raw['EvolState']=='RC'))\n",
        "rcnans=np.isnan(ageRC) #removing nans from this version of the table.\n",
        "ageRC[rcnans]=0\n",
        "ageRGB=np.array(apokasc3raw['AgeRGB']*(apokasc3raw['EvolState']=='RGB'))\n",
        "rgbnans=np.isnan(ageRGB) #removing nans from this version of the table.\n",
        "ageRGB[rgbnans]=0\n",
        "apokasc3raw['Age']=(ageRC+ageRGB)\n",
        "\n",
        "hasagea3=np.where((apokasc3raw['Age']==apokasc3raw['Age']) & (apokasc3raw['Age']>0.1))\n",
        "apokasc3=apokasc3raw[hasagea3]\n",
        "apokasc3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "oHzm7xkYpPVD",
        "outputId": "046ca759-d0ea-4771-9a27-97a5d3161981"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Table length=12291>\n",
              "  KIC    EvolState ESSource ...          2MASS            Age  \n",
              "                            ...                                \n",
              " int64      str7     str4   ...          str23          float64\n",
              "-------- --------- -------- ... ----------------------- -------\n",
              "  893214       RGB     Seis ... 2MASS J19245967+3638183  2.8815\n",
              " 1026180        RC     Spec ... 2MASS J19241923+3645378  3.1325\n",
              " 1026309       RGB     Seis ... 2MASS J19242636+3643594  0.5842\n",
              " 1026452        RC     Seis ... 2MASS J19243452+3647244  2.6495\n",
              " 1027110       RGB     Seis ... 2MASS J19250937+3644599  9.0694\n",
              " 1027337       RGB     Seis ... 2MASS J19252021+3647118  5.8519\n",
              " 1027707       RGB     Seis ... 2MASS J19253846+3646103  1.3052\n",
              " 1160655       RGB     Seis ... 2MASS J19232193+3650379  5.7073\n",
              " 1160684        RC     Spec ... 2MASS J19232466+3652089   5.307\n",
              "     ...       ...      ... ...                     ...     ...\n",
              "12784998        RC     Seis ... 2MASS J19211318+5201390  3.3478\n",
              "12785083        RC     Seis ... 2MASS J19212376+5204593  7.3798\n",
              "12785250       RGB     Spec ... 2MASS J19214766+5205365  4.4587\n",
              "12785401       RGB     Seis ... 2MASS J19221167+5202332 15.6194\n",
              "12833300        RC     Seis ... 2MASS J19171503+5207238  8.1186\n",
              "12884116       RGB     Seis ... 2MASS J19182431+5215519  7.6715\n",
              "12884661        RC     Spec ... 2MASS J19192222+5213103  1.7467\n",
              "12884930        RC     Seis ... 2MASS J19200187+5214588  3.2902\n",
              "12885196       RGB     Seis ... 2MASS J19203926+5214210  4.9813"
            ],
            "text/html": [
              "<div><i>Table length=12291</i>\n",
              "<table id=\"table137769437313984\" class=\"table-striped table-bordered table-condensed\">\n",
              "<thead><tr><th>KIC</th><th>EvolState</th><th>ESSource</th><th>CatTab</th><th>SeisSource</th><th>SpecSource</th><th>NNumax</th><th>NDNu</th><th>Nquar</th><th>Numax</th><th>e_Numax</th><th>DNu</th><th>e_DNu</th><th>FDNu</th><th>e_FDNu</th><th>FNumax</th><th>Mass</th><th>e_Mass</th><th>Radius</th><th>e_Radius</th><th>logg-Seis</th><th>e_logg-Seis</th><th>Teff</th><th>e_Teff</th><th>logg-Spec</th><th>e_logg-Spec</th><th>[Fe/H]</th><th>e_[Fe/H]</th><th>[a/Fe]</th><th>e_[a/Fe]</th><th>[C/Fe]</th><th>e_[C/Fe]</th><th>[N/Fe]</th><th>e_[N/Fe]</th><th>InvRGaia</th><th>e_InvRGaia</th><th>AgeCat</th><th>AgeRGB</th><th>E_AgeRGB</th><th>e_AgeRGB</th><th>AgeRC</th><th>E_AgeRC</th><th>e_AgeRC</th><th>vsini</th><th>alphaCat</th><th>GaiaDR3</th><th>2MASS</th><th>Age</th></tr></thead>\n",
              "<thead><tr><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th>uHz</th><th>uHz</th><th>uHz</th><th>uHz</th><th></th><th></th><th></th><th>solMass</th><th>solMass</th><th>Rsun</th><th>Rsun</th><th>dex(cm / s2)</th><th>dex(cm / s2)</th><th>K</th><th>K</th><th>dex(cm / s2)</th><th>dex(cm / s2)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th></th><th></th><th></th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th>km / s</th><th></th><th></th><th></th><th></th></tr></thead>\n",
              "<thead><tr><th>int64</th><th>str7</th><th>str4</th><th>str8</th><th>str4</th><th>str4</th><th>int64</th><th>int64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str7</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str5</th><th>int64</th><th>str23</th><th>float64</th></tr></thead>\n",
              "<tr><td>893214</td><td>RGB</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>15</td><td>40.5841</td><td>0.2874</td><td>4.3254</td><td>0.0289</td><td>1.0277</td><td>0.005</td><td>0.9976</td><td>1.4404</td><td>0.0602</td><td>11.0014</td><td>0.2055</td><td>2.5146</td><td>0.0042</td><td>4718.9233</td><td>44.7811</td><td>2.4559</td><td>0.058</td><td>-0.2617</td><td>0.058</td><td>0.0815</td><td>0.022</td><td>-0.0626</td><td>0.0135</td><td>0.2483</td><td>0.0164</td><td>0.082389</td><td>0.002866</td><td>RGB</td><td>2.8815</td><td>0.298</td><td>-0.2639</td><td>2.8815</td><td>0.298</td><td>-0.2639</td><td>0.0</td><td>Apoor</td><td>2050237616959273728</td><td>2MASS J19245967+3638183</td><td>2.8815</td></tr>\n",
              "<tr><td>1026180</td><td>RC</td><td>Spec</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>4</td><td>35.6089</td><td>0.2338</td><td>3.9208</td><td>0.0265</td><td>0.9972</td><td>0.005</td><td>0.9936</td><td>1.5334</td><td>0.0633</td><td>12.2361</td><td>0.2278</td><td>2.4512</td><td>0.0039</td><td>4576.1016</td><td>40.5161</td><td>2.4066</td><td>0.058</td><td>0.2741</td><td>0.058</td><td>0.0215</td><td>0.022</td><td>0.0568</td><td>0.0084</td><td>0.3647</td><td>0.0107</td><td>0.085599</td><td>0.002161</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>3.1325</td><td>0.2754</td><td>-0.1905</td><td>0.0</td><td>Apoor</td><td>2050237174589477888</td><td>2MASS J19241923+3645378</td><td>3.1325</td></tr>\n",
              "<tr><td>1026309</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>8</td><td>4</td><td>18</td><td>16.6974</td><td>0.5675</td><td>1.9432</td><td>0.0805</td><td>1.0072</td><td>0.005</td><td>1.0205</td><td>2.642</td><td>0.518</td><td>23.2678</td><td>2.0993</td><td>2.1176</td><td>0.0148</td><td>4479.2246</td><td>39.7068</td><td>2.2388</td><td>0.058</td><td>0.1609</td><td>0.058</td><td>-0.0295</td><td>0.022</td><td>-0.0823</td><td>0.0088</td><td>0.2913</td><td>0.011</td><td>0.047943</td><td>0.001239</td><td>RGB_AGB</td><td>0.5842</td><td>0.1481</td><td>-0.109</td><td>0.7082</td><td>0.1832</td><td>-0.1405</td><td>0.0</td><td>Apoor</td><td>2050236934071312384</td><td>2MASS J19242636+3643594</td><td>0.5842</td></tr>\n",
              "<tr><td>1026452</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>18</td><td>34.3652</td><td>0.2256</td><td>3.9749</td><td>0.0268</td><td>0.9953</td><td>0.005</td><td>0.9936</td><td>1.4618</td><td>0.0599</td><td>11.9485</td><td>0.2215</td><td>2.451</td><td>0.0044</td><td>4910.6035</td><td>53.0693</td><td>2.4907</td><td>0.058</td><td>-0.2652</td><td>0.058</td><td>0.0658</td><td>0.022</td><td>0.0005</td><td>0.0189</td><td>0.1605</td><td>0.0222</td><td>0.075937</td><td>0.003795</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>2.6495</td><td>0.2319</td><td>-0.1919</td><td>0.0</td><td>Apoor</td><td>2050243050104808960</td><td>2MASS J19243452+3647244</td><td>2.6495</td></tr>\n",
              "<tr><td>1027110</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>8</td><td>4</td><td>18</td><td>6.5198</td><td>0.1616</td><td>1.1613</td><td>0.044</td><td>1.0511</td><td>0.005</td><td>1.0535</td><td>1.0367</td><td>0.1769</td><td>23.337</td><td>1.8791</td><td>1.6949</td><td>0.011</td><td>4194.4375</td><td>37.9582</td><td>1.7495</td><td>0.058</td><td>-0.3017</td><td>0.058</td><td>0.2615</td><td>0.022</td><td>0.1451</td><td>0.0109</td><td>0.1366</td><td>0.0131</td><td>0.040245</td><td>0.001509</td><td>RGB_AGB</td><td>9.0694</td><td>8.0551</td><td>-3.8133</td><td>7.2088</td><td>4.6171</td><td>-2.3475</td><td>0.0</td><td>Arich</td><td>2050239201814200192</td><td>2MASS J19250937+3644599</td><td>9.0694</td></tr>\n",
              "<tr><td>1027337</td><td>RGB</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>18</td><td>74.3689</td><td>0.4491</td><td>6.9661</td><td>0.0418</td><td>1.0282</td><td>0.005</td><td>0.9959</td><td>1.2676</td><td>0.0489</td><td>7.6702</td><td>0.133</td><td>2.7732</td><td>0.0038</td><td>4621.996</td><td>41.3674</td><td>2.7836</td><td>0.058</td><td>0.2081</td><td>0.058</td><td>0.0354</td><td>0.022</td><td>0.062</td><td>0.009</td><td>0.2898</td><td>0.0115</td><td>0.123008</td><td>0.0033</td><td>RGB</td><td>5.8519</td><td>0.5953</td><td>-0.5247</td><td>5.8519</td><td>0.5953</td><td>-0.5247</td><td>0.0</td><td>Apoor</td><td>2050240782362231552</td><td>2MASS J19252021+3647118</td><td>5.8519</td></tr>\n",
              "<tr><td>1027707</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>6</td><td>3</td><td>18</td><td>3.0206</td><td>0.0885</td><td>0.5593</td><td>0.0309</td><td>1.0265</td><td>0.005</td><td>1.0663</td><td>2.0033</td><td>0.4792</td><td>48.0566</td><td>5.5208</td><td>1.3484</td><td>0.0129</td><td>3961.365</td><td>35.9864</td><td>1.4062</td><td>0.058</td><td>0.1105</td><td>0.058</td><td>0.0356</td><td>0.022</td><td>0.0455</td><td>0.0079</td><td>0.1751</td><td>0.0094</td><td>0.018104</td><td>0.001509</td><td>RGB_AGB</td><td>1.3052</td><td>0.6198</td><td>-0.3779</td><td>1.5494</td><td>0.4593</td><td>-0.4138</td><td>0.0</td><td>Apoor</td><td>2050240129527252096</td><td>2MASS J19253846+3646103</td><td>1.3052</td></tr>\n",
              "<tr><td>1160655</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>5</td><td>2</td><td>18</td><td>1.5726</td><td>0.0502</td><td>0.3698</td><td>0.024</td><td>1.0608</td><td>0.005</td><td>1.0525</td><td>1.1903</td><td>0.3305</td><td>52.0838</td><td>6.9807</td><td>1.058</td><td>0.0139</td><td>3837.788</td><td>33.9314</td><td>0.9088</td><td>0.058</td><td>-0.1446</td><td>0.058</td><td>0.1098</td><td>0.022</td><td>0.0582</td><td>0.0089</td><td>0.2023</td><td>0.0105</td><td>0.018767</td><td>0.001236</td><td>RGB_AGB</td><td>5.7073</td><td>8.7454</td><td>-2.777</td><td>5.013</td><td>5.3362</td><td>-2.0267</td><td>0.0</td><td>Arich</td><td>2050252395953454464</td><td>2MASS J19232193+3650379</td><td>5.7073</td></tr>\n",
              "<tr><td>1160684</td><td>RC</td><td>Spec</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>17</td><td>26.8674</td><td>0.1516</td><td>3.5003</td><td>0.0212</td><td>0.9981</td><td>0.005</td><td>0.9936</td><td>1.1208</td><td>0.0426</td><td>11.8817</td><td>0.2048</td><td>2.3406</td><td>0.0043</td><td>4830.3506</td><td>56.4954</td><td>2.382</td><td>0.058</td><td>-0.3194</td><td>0.058</td><td>0.0803</td><td>0.022</td><td>0.0102</td><td>0.0231</td><td>0.1651</td><td>0.0262</td><td>0.086569</td><td>0.008578</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>5.307</td><td>0.4989</td><td>-0.4825</td><td>0.0</td><td>Apoor</td><td>2050254113940398976</td><td>2MASS J19232466+3652089</td><td>5.307</td></tr>\n",
              "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
              "<tr><td>12784998</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>4</td><td>34.0536</td><td>0.2236</td><td>3.9132</td><td>0.0264</td><td>0.9975</td><td>0.005</td><td>0.9936</td><td>1.4124</td><td>0.0582</td><td>11.9181</td><td>0.2214</td><td>2.4383</td><td>0.004</td><td>4716.2725</td><td>43.5629</td><td>2.3982</td><td>0.058</td><td>0.0163</td><td>0.058</td><td>-0.0027</td><td>0.022</td><td>-0.0848</td><td>0.0109</td><td>0.2845</td><td>0.0137</td><td>0.08903</td><td>0.001833</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>3.3478</td><td>0.3085</td><td>-0.2419</td><td>0.0</td><td>Apoor</td><td>2139268440716719104</td><td>2MASS J19211318+5201390</td><td>3.3478</td></tr>\n",
              "<tr><td>12785083</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>10</td><td>7</td><td>9</td><td>28.1868</td><td>0.1418</td><td>3.6217</td><td>0.0208</td><td>1.0005</td><td>0.005</td><td>0.9936</td><td>1.062</td><td>0.0389</td><td>11.3888</td><td>0.1898</td><td>2.3539</td><td>0.0036</td><td>4667.458</td><td>43.0416</td><td>2.3718</td><td>0.058</td><td>-0.0811</td><td>0.058</td><td>0.111</td><td>0.022</td><td>0.1162</td><td>0.0114</td><td>0.1623</td><td>0.0141</td><td>0.090954</td><td>0.002337</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>7.3798</td><td>0.7808</td><td>-0.8104</td><td>0.0</td><td>Arich</td><td>2139269029129367936</td><td>2MASS J19212376+5204593</td><td>7.3798</td></tr>\n",
              "<tr><td>12785250</td><td>RGB</td><td>Spec</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>8</td><td>33.052</td><td>0.1996</td><td>3.8806</td><td>0.0233</td><td>1.0322</td><td>0.005</td><td>1.001</td><td>1.2168</td><td>0.0468</td><td>11.1475</td><td>0.1929</td><td>2.4285</td><td>0.0044</td><td>4784.141</td><td>54.5634</td><td>2.4946</td><td>0.058</td><td>-0.3854</td><td>0.058</td><td>0.0774</td><td>0.022</td><td>0.0512</td><td>0.023</td><td>0.1515</td><td>0.026</td><td>0.082623</td><td>0.003763</td><td>RGB</td><td>4.4587</td><td>0.5163</td><td>-0.4558</td><td>4.4587</td><td>0.5163</td><td>-0.4558</td><td>0.0</td><td>Apoor</td><td>2139269574588790400</td><td>2MASS J19214766+5205365</td><td>4.4587</td></tr>\n",
              "<tr><td>12785401</td><td>RGB</td><td>Seis</td><td>Silver</td><td>WAvg</td><td>DR17</td><td>5</td><td>3</td><td>2</td><td>15.9445</td><td>0.6038</td><td>2.2933</td><td>0.106</td><td>1.0492</td><td>0.005</td><td>1.0221</td><td>0.9582</td><td>0.2093</td><td>14.4591</td><td>1.4539</td><td>2.0897</td><td>0.0164</td><td>4319.34</td><td>37.8322</td><td>2.1878</td><td>0.058</td><td>0.2022</td><td>0.058</td><td>0.0451</td><td>0.022</td><td>0.0492</td><td>0.0081</td><td>0.2587</td><td>0.0101</td><td>0.042488</td><td>0.004795</td><td>RGB_AGB</td><td>15.6194</td><td>22.9696</td><td>-8.2623</td><td>11.4791</td><td>9.5467</td><td>-4.6335</td><td>0.0</td><td>Apoor</td><td>2139266383430424704</td><td>2MASS J19221167+5202332</td><td>15.6194</td></tr>\n",
              "<tr><td>12833300</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>4</td><td>29.7501</td><td>0.1953</td><td>3.7547</td><td>0.0253</td><td>1.0</td><td>0.005</td><td>0.9936</td><td>1.057</td><td>0.0437</td><td>11.1049</td><td>0.2067</td><td>2.3738</td><td>0.004</td><td>4592.0396</td><td>41.4076</td><td>2.3874</td><td>0.058</td><td>0.0764</td><td>0.058</td><td>0.0741</td><td>0.022</td><td>0.0955</td><td>0.0097</td><td>0.19</td><td>0.0123</td><td>0.092623</td><td>0.00185</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>8.1186</td><td>0.9279</td><td>-0.877</td><td>0.0</td><td>Arich</td><td>2139492607946187648</td><td>2MASS J19171503+5207238</td><td>8.1186</td></tr>\n",
              "<tr><td>12884116</td><td>RGB</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>8</td><td>50.7865</td><td>0.3067</td><td>5.3917</td><td>0.0323</td><td>1.0334</td><td>0.005</td><td>0.9959</td><td>1.1107</td><td>0.0428</td><td>8.6775</td><td>0.1504</td><td>2.6086</td><td>0.0038</td><td>4645.334</td><td>42.5837</td><td>2.6754</td><td>0.058</td><td>-0.0631</td><td>0.058</td><td>0.0762</td><td>0.022</td><td>-0.0168</td><td>0.0111</td><td>0.0832</td><td>0.0138</td><td>0.115544</td><td>0.002715</td><td>RGB</td><td>7.6715</td><td>1.0086</td><td>-0.7863</td><td>7.6715</td><td>1.0086</td><td>-0.7863</td><td>0.0</td><td>Apoor</td><td>2139312837795971840</td><td>2MASS J19182431+5215519</td><td>7.6715</td></tr>\n",
              "<tr><td>12884661</td><td>RC</td><td>Spec</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>7</td><td>5</td><td>2</td><td>31.3348</td><td>0.2057</td><td>3.3249</td><td>0.0224</td><td>1.0066</td><td>0.005</td><td>0.9936</td><td>1.9154</td><td>0.0792</td><td>14.617</td><td>0.2722</td><td>2.3933</td><td>0.0041</td><td>4528.001</td><td>42.9468</td><td>2.362</td><td>0.058</td><td>0.2678</td><td>0.058</td><td>0.0227</td><td>0.022</td><td>0.0588</td><td>0.0102</td><td>0.1852</td><td>0.0127</td><td>0.093641</td><td>0.002865</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>1.7467</td><td>0.1161</td><td>-0.0863</td><td>0.0</td><td>Apoor</td><td>2139309298742652672</td><td>2MASS J19192222+5213103</td><td>1.7467</td></tr>\n",
              "<tr><td>12884930</td><td>RC</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>9</td><td>6</td><td>10</td><td>37.868</td><td>0.214</td><td>4.3441</td><td>0.0275</td><td>0.9952</td><td>0.005</td><td>0.9936</td><td>1.3724</td><td>0.0531</td><td>11.0282</td><td>0.1945</td><td>2.4933</td><td>0.0041</td><td>4912.165</td><td>53.7385</td><td>2.6052</td><td>0.058</td><td>-0.1505</td><td>0.058</td><td>0.0384</td><td>0.022</td><td>-0.0195</td><td>0.0186</td><td>0.2159</td><td>0.0219</td><td>0.094262</td><td>0.003407</td><td>RC</td><td>--</td><td>--</td><td>--</td><td>3.2902</td><td>0.29</td><td>-0.2246</td><td>0.0</td><td>Apoor</td><td>2139321324651126400</td><td>2MASS J19200187+5214588</td><td>3.2902</td></tr>\n",
              "<tr><td>12885196</td><td>RGB</td><td>Seis</td><td>Gold</td><td>WAvg</td><td>DR17</td><td>8</td><td>5</td><td>16</td><td>92.436</td><td>0.6547</td><td>8.2023</td><td>0.0549</td><td>1.0245</td><td>0.005</td><td>0.9959</td><td>1.3182</td><td>0.0551</td><td>6.9858</td><td>0.1305</td><td>2.8713</td><td>0.0043</td><td>4702.0967</td><td>46.9819</td><td>2.8123</td><td>0.058</td><td>0.1631</td><td>0.058</td><td>0.0282</td><td>0.022</td><td>-0.0045</td><td>0.0125</td><td>0.3491</td><td>0.0154</td><td>0.144815</td><td>0.003531</td><td>RGB</td><td>4.9813</td><td>0.553</td><td>-0.4742</td><td>4.9813</td><td>0.553</td><td>-0.4742</td><td>0.0</td><td>Apoor</td><td>2139321977486192640</td><td>2MASS J19203926+5214210</td><td>4.9813</td></tr>\n",
              "</table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agedata= apokasc3#pick a dataset"
      ],
      "metadata": {
        "id": "_u5hh1XtpMoK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Option 1 TESS Theodoridis et al. 2025\n",
        "#intersect, ind_a, ind_b = np.intersect1d(data_masked['tic_v8_id'],agedata['TIC'], return_indices=True)\n",
        "\n",
        "#Option 2 APOKASC-2 Pinsonneault et al. 2018\n",
        "#intersect, ind_a, ind_b = np.intersect1d(data_masked['sdss4_apogee_id'],agedata['2MASS'], return_indices=True)\n",
        "\n",
        "#Option 3 APOKASC-3 Pinsonneault et al. 2025\n",
        "intersect, ind_a, ind_b = np.intersect1d(data_masked['gaia_dr3_source_id'],agedata['GaiaDR3'], return_indices=True)\n",
        "\n",
        "#Option 4 APO-K2 Warfield et al. 2024\n",
        "#intersect, ind_a, ind_b = np.intersect1d(data_masked['sdss4_apogee_id'],agedata['APOGEE'], return_indices=True)\n",
        "\n",
        "print(len(ind_b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYzZcYZlpIgV",
        "outputId": "300a059f-6030-410a-885a-6ab085637388"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "np-OuPVppGUx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullx = np.dstack([data_masked['teff'][ind_a],data_masked['logg'][ind_a], data_masked['m_h_atm'][ind_a],\n",
        "                   data_masked['alpha_m_atm'][ind_a], data_masked['c_h'][ind_a], data_masked['n_h'][ind_a]])[0]\n",
        "\n",
        "fully = np.dstack([agedata['Age'][ind_b]])[0] #for Pinsonneault 2018\n",
        "\n",
        "#remove non-finite entries!\n",
        "mask = np.all(np.isfinite(fullx), axis=1) & np.all(np.isfinite(fully), axis=1)\n",
        "fullx, fully = fullx[mask], fully[mask]\n",
        "\n",
        "scaling_x = np.median(fullx, axis=0)\n",
        "scaling_y = np.median(fully, axis=0)\n",
        "\n",
        "fullx, fully = fullx/scaling_x, fully/scaling_y"
      ],
      "metadata": {
        "id": "kik-HqmQo7ZA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pick some numbers\n",
        "neurons_per_layer=20\n",
        "layers=3\n",
        "iterations=100"
      ],
      "metadata": {
        "id": "e_Wjj30Go7WZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#start with an input layer\n",
        "inputs = keras.Input(shape=(6,))\n",
        "#now we add the Dense layers (indicating the previous layer in the brackets following the layer declaration\n",
        "\n",
        "#change this part if you're changing the number of layers\n",
        "layer1 =keras.layers.Dense(neurons_per_layer, activation='relu')(inputs)\n",
        "layer2 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer1)\n",
        "layer3 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer2)\n",
        "layer4 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer3)\n",
        "layer5 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer4)\n",
        "layer6 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer5)\n",
        "layer7 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer6)\n",
        "layer8 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer7)\n",
        "layer9 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer8)\n",
        "layer10 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer9)\n",
        "layer11 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer10)\n",
        "layer12 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer11)\n",
        "layer13 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer12)\n",
        "layer14 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer13)\n",
        "layer15 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer14)\n",
        "layer16 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer15)\n",
        "layer17 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer16)\n",
        "layer18 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer17)\n",
        "layer19 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer18)\n",
        "layer20 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer19)\n",
        "layer21 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer20)\n",
        "layer22 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer21)\n",
        "layer23 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer22)\n",
        "\n",
        "#then the output layer YOU ALSO HAVE TO MAKE THIS MATCH YOUR NUMBER OF LAYERS\n",
        "outputs = keras.layers.Dense(1)(layer4)\n",
        "\n",
        "\n",
        "# then we put that all together in the Model object\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='test')\n",
        "#and we can print a summary to check it all went to plan\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "jEAwRetro7Sv",
        "outputId": "20a71423-2bd6-4fed-ceb9-dba8bd8fd09d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"test\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"test\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m140\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,421\u001b[0m (5.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421</span> (5.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,421\u001b[0m (5.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421</span> (5.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AtroRoado7KN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tenpercent=len(agedata['Age'][ind_b])//10 #figure out what ten percent of this set of age data is\n",
        "\n",
        "#last name before M\n",
        "trainbin=slice(0,-1*tenpercent-1)\n",
        "testing=slice(-1*tenpercent,-1)\n",
        "\n",
        "\n",
        "#last name M or later\n",
        "#trainbin=slice(tenpecent+1,-1)\n",
        "#testing=slice(0,tenpercent)\n",
        "\n",
        "\n",
        "x_train, y_train = fullx[trainbin], fully[trainbin]\n",
        "x_test, y_test = fullx[testing], fully[testing]"
      ],
      "metadata": {
        "id": "wRkV8s0soy7X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=iterations, validation_split=0.05, batch_size=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "697Lgf-yogbN",
        "outputId": "9e200395-948c-4e08-fab0-97d951738db7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 3.9188 - val_accuracy: 0.0000e+00 - val_loss: 0.8683\n",
            "Epoch 2/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.8737 - val_accuracy: 0.0000e+00 - val_loss: 0.7131\n",
            "Epoch 3/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.7571 - val_accuracy: 0.0000e+00 - val_loss: 0.6423\n",
            "Epoch 4/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.7285 - val_accuracy: 0.0000e+00 - val_loss: 0.5820\n",
            "Epoch 5/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6437 - val_accuracy: 0.0000e+00 - val_loss: 0.5526\n",
            "Epoch 6/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6470 - val_accuracy: 0.0000e+00 - val_loss: 0.5573\n",
            "Epoch 7/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6446 - val_accuracy: 0.0000e+00 - val_loss: 0.5498\n",
            "Epoch 8/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6073 - val_accuracy: 0.0000e+00 - val_loss: 0.5369\n",
            "Epoch 9/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6181 - val_accuracy: 0.0000e+00 - val_loss: 0.5185\n",
            "Epoch 10/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6828 - val_accuracy: 0.0000e+00 - val_loss: 0.5199\n",
            "Epoch 11/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6745 - val_accuracy: 0.0000e+00 - val_loss: 0.5305\n",
            "Epoch 12/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5863 - val_accuracy: 0.0000e+00 - val_loss: 0.5228\n",
            "Epoch 13/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6306 - val_accuracy: 0.0000e+00 - val_loss: 0.5149\n",
            "Epoch 14/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6419 - val_accuracy: 0.0000e+00 - val_loss: 0.5071\n",
            "Epoch 15/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5657 - val_accuracy: 0.0000e+00 - val_loss: 0.5328\n",
            "Epoch 16/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.5712 - val_accuracy: 0.0000e+00 - val_loss: 0.5126\n",
            "Epoch 17/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5581 - val_accuracy: 0.0000e+00 - val_loss: 0.5052\n",
            "Epoch 18/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5671 - val_accuracy: 0.0000e+00 - val_loss: 0.5021\n",
            "Epoch 19/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5921 - val_accuracy: 0.0000e+00 - val_loss: 0.5041\n",
            "Epoch 20/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5602 - val_accuracy: 0.0000e+00 - val_loss: 0.5039\n",
            "Epoch 21/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5604 - val_accuracy: 0.0000e+00 - val_loss: 0.5063\n",
            "Epoch 22/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.5054 - val_accuracy: 0.0000e+00 - val_loss: 0.5002\n",
            "Epoch 23/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5423 - val_accuracy: 0.0000e+00 - val_loss: 0.4953\n",
            "Epoch 24/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5616 - val_accuracy: 0.0000e+00 - val_loss: 0.5101\n",
            "Epoch 25/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5301 - val_accuracy: 0.0000e+00 - val_loss: 0.4995\n",
            "Epoch 26/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5810 - val_accuracy: 0.0000e+00 - val_loss: 0.4968\n",
            "Epoch 27/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5188 - val_accuracy: 0.0000e+00 - val_loss: 0.5020\n",
            "Epoch 28/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5713 - val_accuracy: 0.0000e+00 - val_loss: 0.5014\n",
            "Epoch 29/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.5146 - val_accuracy: 0.0000e+00 - val_loss: 0.5019\n",
            "Epoch 30/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5537 - val_accuracy: 0.0000e+00 - val_loss: 0.4939\n",
            "Epoch 31/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.4724 - val_accuracy: 0.0000e+00 - val_loss: 0.5030\n",
            "Epoch 32/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5674 - val_accuracy: 0.0000e+00 - val_loss: 0.4868\n",
            "Epoch 33/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5667 - val_accuracy: 0.0000e+00 - val_loss: 0.4961\n",
            "Epoch 34/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5759 - val_accuracy: 0.0000e+00 - val_loss: 0.5297\n",
            "Epoch 35/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.6091 - val_accuracy: 0.0000e+00 - val_loss: 0.5361\n",
            "Epoch 36/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5479 - val_accuracy: 0.0000e+00 - val_loss: 0.4954\n",
            "Epoch 37/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5727 - val_accuracy: 0.0000e+00 - val_loss: 0.4918\n",
            "Epoch 38/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5068 - val_accuracy: 0.0000e+00 - val_loss: 0.4867\n",
            "Epoch 39/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.4955 - val_accuracy: 0.0000e+00 - val_loss: 0.5002\n",
            "Epoch 40/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5926 - val_accuracy: 0.0000e+00 - val_loss: 0.4876\n",
            "Epoch 41/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5656 - val_accuracy: 0.0000e+00 - val_loss: 0.4873\n",
            "Epoch 42/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5971 - val_accuracy: 0.0000e+00 - val_loss: 0.4848\n",
            "Epoch 43/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5522 - val_accuracy: 0.0000e+00 - val_loss: 0.4949\n",
            "Epoch 44/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.4945 - val_accuracy: 0.0000e+00 - val_loss: 0.4887\n",
            "Epoch 45/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5827 - val_accuracy: 0.0000e+00 - val_loss: 0.4913\n",
            "Epoch 46/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5628 - val_accuracy: 0.0000e+00 - val_loss: 0.4896\n",
            "Epoch 47/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5273 - val_accuracy: 0.0000e+00 - val_loss: 0.4845\n",
            "Epoch 48/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.5653 - val_accuracy: 0.0000e+00 - val_loss: 0.4897\n",
            "Epoch 49/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5297 - val_accuracy: 0.0000e+00 - val_loss: 0.4856\n",
            "Epoch 50/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5490 - val_accuracy: 0.0000e+00 - val_loss: 0.4937\n",
            "Epoch 51/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5422 - val_accuracy: 0.0000e+00 - val_loss: 0.4912\n",
            "Epoch 52/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.4944 - val_accuracy: 0.0000e+00 - val_loss: 0.4961\n",
            "Epoch 53/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5693 - val_accuracy: 0.0000e+00 - val_loss: 0.4830\n",
            "Epoch 54/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5575 - val_accuracy: 0.0000e+00 - val_loss: 0.4935\n",
            "Epoch 55/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5149 - val_accuracy: 0.0000e+00 - val_loss: 0.4940\n",
            "Epoch 56/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5521 - val_accuracy: 0.0000e+00 - val_loss: 0.4896\n",
            "Epoch 57/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.4989 - val_accuracy: 0.0000e+00 - val_loss: 0.4967\n",
            "Epoch 58/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5743 - val_accuracy: 0.0000e+00 - val_loss: 0.4899\n",
            "Epoch 59/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5917 - val_accuracy: 0.0000e+00 - val_loss: 0.5075\n",
            "Epoch 60/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.5344 - val_accuracy: 0.0000e+00 - val_loss: 0.4797\n",
            "Epoch 61/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4970 - val_accuracy: 0.0000e+00 - val_loss: 0.4814\n",
            "Epoch 62/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4977 - val_accuracy: 0.0000e+00 - val_loss: 0.4808\n",
            "Epoch 63/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.5551 - val_accuracy: 0.0000e+00 - val_loss: 0.4859\n",
            "Epoch 64/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.6395 - val_accuracy: 0.0000e+00 - val_loss: 0.4788\n",
            "Epoch 65/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.4900 - val_accuracy: 0.0000e+00 - val_loss: 0.4799\n",
            "Epoch 66/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5093 - val_accuracy: 0.0000e+00 - val_loss: 0.5110\n",
            "Epoch 67/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.5951 - val_accuracy: 0.0000e+00 - val_loss: 0.4877\n",
            "Epoch 68/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.5510 - val_accuracy: 0.0000e+00 - val_loss: 0.4835\n",
            "Epoch 69/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.4989 - val_accuracy: 0.0000e+00 - val_loss: 0.4862\n",
            "Epoch 70/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5724 - val_accuracy: 0.0000e+00 - val_loss: 0.4806\n",
            "Epoch 71/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5162 - val_accuracy: 0.0000e+00 - val_loss: 0.4842\n",
            "Epoch 72/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5206 - val_accuracy: 0.0000e+00 - val_loss: 0.4950\n",
            "Epoch 73/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.4743 - val_accuracy: 0.0000e+00 - val_loss: 0.4839\n",
            "Epoch 74/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5160 - val_accuracy: 0.0000e+00 - val_loss: 0.4886\n",
            "Epoch 75/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5271 - val_accuracy: 0.0000e+00 - val_loss: 0.4892\n",
            "Epoch 76/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5438 - val_accuracy: 0.0000e+00 - val_loss: 0.4837\n",
            "Epoch 77/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5607 - val_accuracy: 0.0000e+00 - val_loss: 0.4773\n",
            "Epoch 78/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5199 - val_accuracy: 0.0000e+00 - val_loss: 0.4866\n",
            "Epoch 79/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5547 - val_accuracy: 0.0000e+00 - val_loss: 0.4824\n",
            "Epoch 80/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5104 - val_accuracy: 0.0000e+00 - val_loss: 0.4832\n",
            "Epoch 81/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5520 - val_accuracy: 0.0000e+00 - val_loss: 0.4953\n",
            "Epoch 82/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5397 - val_accuracy: 0.0000e+00 - val_loss: 0.4885\n",
            "Epoch 83/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5219 - val_accuracy: 0.0000e+00 - val_loss: 0.4843\n",
            "Epoch 84/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.5532 - val_accuracy: 0.0000e+00 - val_loss: 0.4882\n",
            "Epoch 85/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5351 - val_accuracy: 0.0000e+00 - val_loss: 0.4774\n",
            "Epoch 86/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5235 - val_accuracy: 0.0000e+00 - val_loss: 0.4845\n",
            "Epoch 87/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5494 - val_accuracy: 0.0000e+00 - val_loss: 0.4894\n",
            "Epoch 88/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5635 - val_accuracy: 0.0000e+00 - val_loss: 0.4795\n",
            "Epoch 89/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5363 - val_accuracy: 0.0000e+00 - val_loss: 0.4800\n",
            "Epoch 90/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.5108 - val_accuracy: 0.0000e+00 - val_loss: 0.4863\n",
            "Epoch 91/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.4768 - val_accuracy: 0.0000e+00 - val_loss: 0.4864\n",
            "Epoch 92/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5201 - val_accuracy: 0.0000e+00 - val_loss: 0.4848\n",
            "Epoch 93/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5194 - val_accuracy: 0.0000e+00 - val_loss: 0.4955\n",
            "Epoch 94/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5589 - val_accuracy: 0.0000e+00 - val_loss: 0.5022\n",
            "Epoch 95/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5500 - val_accuracy: 0.0000e+00 - val_loss: 0.4845\n",
            "Epoch 96/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5852 - val_accuracy: 0.0000e+00 - val_loss: 0.4860\n",
            "Epoch 97/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5895 - val_accuracy: 0.0000e+00 - val_loss: 0.4784\n",
            "Epoch 98/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6020 - val_accuracy: 0.0000e+00 - val_loss: 0.4745\n",
            "Epoch 99/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5688 - val_accuracy: 0.0000e+00 - val_loss: 0.4873\n",
            "Epoch 100/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.5408 - val_accuracy: 0.0000e+00 - val_loss: 0.4892\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d4bf7c6a960>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "print(len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoThiCu0ogYo",
        "outputId": "d67ff448-69bd-461e-b559-cb819fbd32a0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "1189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric=0.3 #is the accuracy better than 30%?\n",
        "goodfit=np.where(((1-metric) < predictions/y_test) & ((1+metric) > predictions/y_test))\n",
        "badfit=np.where(((1-metric) > predictions/y_test) | ((1+metric) < predictions/y_test))\n",
        "\n",
        "print ('With ', neurons_per_layer, 'neurons per layer, ', layers, 'layers, and ', iterations, 'iterations')\n",
        "print ('using the training set', trainbin)\n",
        "print (len(goodfit[0])/len(y_test)*100, 'percent of the ages are good')\n",
        "print (len(badfit[0])/len(y_test)*100, 'percent of the ages are bad')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W5MsGbUogWB",
        "outputId": "f86c09df-f4fd-4669-c463-00f8bb141ded"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With  20 neurons per layer,  3 layers, and  100 iterations\n",
            "using the training set slice(0, -1191, None)\n",
            "66.3582842724979 percent of the ages are good\n",
            "33.6417157275021 percent of the ages are bad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DR19x = np.dstack([data_masked['teff'],data_masked['logg'], data_masked['m_h_atm'],\n",
        "                   data_masked['alpha_m_atm'], data_masked['c_h'], data_masked['n_h']])[0]\n",
        "print(len(data_masked['teff']))\n",
        "\n",
        "DR19x= DR19x/scaling_x\n",
        "predictionsDR19 = model.predict(DR19x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv9wI6IaogS5",
        "outputId": "ec676048-a089-4efd-f0ef-9c411d716419"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "963539\n",
            "\u001b[1m30111/30111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agedata2= tess"
      ],
      "metadata": {
        "id": "YtmjfHSeogGb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersect2, ind_a2, ind_b2 = np.intersect1d(data_masked['tic_v8_id'],agedata2['TIC'], return_indices=True)"
      ],
      "metadata": {
        "id": "YeA29W4Bof8Q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullx2 = np.dstack([data_masked['teff'][ind_a2],data_masked['logg'][ind_a2], data_masked['m_h_atm'][ind_a2],\n",
        "                   data_masked['alpha_m_atm'][ind_a2], data_masked['c_h'][ind_a2], data_masked['n_h'][ind_a2]])[0]\n",
        "\n",
        "fully2 = np.dstack([agedata2['Age'][ind_b2]])[0] #for Pinsonneault 2018\n",
        "\n",
        "#remove non-finite entries!\n",
        "mask2 = np.all(np.isfinite(fullx2), axis=1) & np.all(np.isfinite(fully2), axis=1)\n",
        "fullx2, fully2 = fullx2[mask2], fully2[mask2]\n",
        "\n",
        "scaling_x2 = np.median(fullx2, axis=0)\n",
        "scaling_y2 = np.median(fully2, axis=0)\n",
        "\n",
        "fullx2, fully2 = fullx2/scaling_x2, fully2/scaling_y2"
      ],
      "metadata": {
        "id": "Mfiw5-xEobNI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start with an input layer\n",
        "inputs = keras.Input(shape=(6,))\n",
        "#now we add the Dense layers (indicating the previous layer in the brackets following the layer declaration\n",
        "\n",
        "#change this part if you're changing the number of layers\n",
        "layer1 =keras.layers.Dense(neurons_per_layer, activation='relu')(inputs)\n",
        "layer2 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer1)\n",
        "layer3 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer2)\n",
        "layer4 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer3)\n",
        "layer5 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer4)\n",
        "layer6 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer5)\n",
        "layer7 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer6)\n",
        "layer8 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer7)\n",
        "layer9 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer8)\n",
        "layer10 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer9)\n",
        "layer11 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer10)\n",
        "layer12 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer11)\n",
        "layer13 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer12)\n",
        "layer14 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer13)\n",
        "layer15 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer14)\n",
        "layer16 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer15)\n",
        "layer17 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer16)\n",
        "layer18 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer17)\n",
        "layer19 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer18)\n",
        "layer20 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer19)\n",
        "layer21 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer20)\n",
        "layer22 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer21)\n",
        "layer23 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer22)\n",
        "\n",
        "#then the output layer YOU ALSO HAVE TO MAKE THIS MATCH YOUR NUMBER OF LAYERS\n",
        "outputs = keras.layers.Dense(1)(layer4)\n",
        "\n",
        "\n",
        "# then we put that all together in the Model object\n",
        "model2 = keras.Model(inputs=inputs, outputs=outputs, name='test')\n",
        "#and we can print a summary to check it all went to plan\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "RNJvmvHooX6L",
        "outputId": "6c0bc517-8550-4e6f-f947-d169891e660a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"test\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"test\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m140\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,421\u001b[0m (5.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421</span> (5.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,421\u001b[0m (5.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421</span> (5.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Z4PgHt3IoXbL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tenpercent2=len(agedata2['Age'][ind_b2])//10 #figure out what ten percent of this set of age data is\n",
        "\n",
        "#last name before M\n",
        "trainbin2=slice(0,-1*tenpercent2-1)\n",
        "testing2=slice(-1*tenpercent2,-1)\n",
        "\n",
        "\n",
        "#last name M or later\n",
        "#trainbin=slice(tenpecent+1,-1)\n",
        "#testing=slice(0,tenpercent)\n",
        "\n",
        "\n",
        "x_train2, y_train2 = fullx2[trainbin2], fully2[trainbin2]\n",
        "x_test2, y_test2 = fullx2[testing2], fully2[testing2]"
      ],
      "metadata": {
        "id": "recDa3eXoTmJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(x_train2, y_train2, epochs=iterations, validation_split=0.05, batch_size=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj-Xm9dDoQDC",
        "outputId": "c4c26ab0-6b65-471c-9935-234ffb5d2add"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 0.9694 - val_accuracy: 0.0000e+00 - val_loss: 0.4112\n",
            "Epoch 2/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3874 - val_accuracy: 0.0000e+00 - val_loss: 0.2875\n",
            "Epoch 3/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2917 - val_accuracy: 0.0000e+00 - val_loss: 0.2285\n",
            "Epoch 4/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.2343 - val_accuracy: 0.0000e+00 - val_loss: 0.1904\n",
            "Epoch 5/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.2086 - val_accuracy: 0.0000e+00 - val_loss: 0.1743\n",
            "Epoch 6/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.2078 - val_accuracy: 0.0000e+00 - val_loss: 0.1714\n",
            "Epoch 7/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1941 - val_accuracy: 0.0000e+00 - val_loss: 0.1728\n",
            "Epoch 8/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1988 - val_accuracy: 0.0000e+00 - val_loss: 0.1727\n",
            "Epoch 9/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1996 - val_accuracy: 0.0000e+00 - val_loss: 0.1690\n",
            "Epoch 10/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1983 - val_accuracy: 0.0000e+00 - val_loss: 0.1654\n",
            "Epoch 11/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1892 - val_accuracy: 0.0000e+00 - val_loss: 0.1647\n",
            "Epoch 12/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1915 - val_accuracy: 0.0000e+00 - val_loss: 0.1644\n",
            "Epoch 13/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1971 - val_accuracy: 0.0000e+00 - val_loss: 0.1651\n",
            "Epoch 14/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1944 - val_accuracy: 0.0000e+00 - val_loss: 0.1634\n",
            "Epoch 15/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1942 - val_accuracy: 0.0000e+00 - val_loss: 0.1681\n",
            "Epoch 16/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1838 - val_accuracy: 0.0000e+00 - val_loss: 0.1644\n",
            "Epoch 17/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1903 - val_accuracy: 0.0000e+00 - val_loss: 0.1646\n",
            "Epoch 18/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1949 - val_accuracy: 0.0000e+00 - val_loss: 0.1632\n",
            "Epoch 19/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1955 - val_accuracy: 0.0000e+00 - val_loss: 0.1684\n",
            "Epoch 20/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.2062 - val_accuracy: 0.0000e+00 - val_loss: 0.1636\n",
            "Epoch 21/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.2021 - val_accuracy: 0.0000e+00 - val_loss: 0.1638\n",
            "Epoch 22/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1893 - val_accuracy: 0.0000e+00 - val_loss: 0.1641\n",
            "Epoch 23/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1894 - val_accuracy: 0.0000e+00 - val_loss: 0.1622\n",
            "Epoch 24/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1897 - val_accuracy: 0.0000e+00 - val_loss: 0.1670\n",
            "Epoch 25/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1854 - val_accuracy: 0.0000e+00 - val_loss: 0.1668\n",
            "Epoch 26/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1916 - val_accuracy: 0.0000e+00 - val_loss: 0.1665\n",
            "Epoch 27/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1945 - val_accuracy: 0.0000e+00 - val_loss: 0.1626\n",
            "Epoch 28/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1858 - val_accuracy: 0.0000e+00 - val_loss: 0.1630\n",
            "Epoch 29/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1908 - val_accuracy: 0.0000e+00 - val_loss: 0.1623\n",
            "Epoch 30/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1937 - val_accuracy: 0.0000e+00 - val_loss: 0.1665\n",
            "Epoch 31/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1917 - val_accuracy: 0.0000e+00 - val_loss: 0.1643\n",
            "Epoch 32/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1955 - val_accuracy: 0.0000e+00 - val_loss: 0.1629\n",
            "Epoch 33/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1916 - val_accuracy: 0.0000e+00 - val_loss: 0.1629\n",
            "Epoch 34/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1909 - val_accuracy: 0.0000e+00 - val_loss: 0.1646\n",
            "Epoch 35/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1915 - val_accuracy: 0.0000e+00 - val_loss: 0.1681\n",
            "Epoch 36/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1968 - val_accuracy: 0.0000e+00 - val_loss: 0.1618\n",
            "Epoch 37/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1955 - val_accuracy: 0.0000e+00 - val_loss: 0.1631\n",
            "Epoch 38/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1921 - val_accuracy: 0.0000e+00 - val_loss: 0.1637\n",
            "Epoch 39/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1909 - val_accuracy: 0.0000e+00 - val_loss: 0.1637\n",
            "Epoch 40/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1967 - val_accuracy: 0.0000e+00 - val_loss: 0.1634\n",
            "Epoch 41/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1906 - val_accuracy: 0.0000e+00 - val_loss: 0.1648\n",
            "Epoch 42/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1897 - val_accuracy: 0.0000e+00 - val_loss: 0.1623\n",
            "Epoch 43/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1835 - val_accuracy: 0.0000e+00 - val_loss: 0.1626\n",
            "Epoch 44/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1863 - val_accuracy: 0.0000e+00 - val_loss: 0.1627\n",
            "Epoch 45/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1852 - val_accuracy: 0.0000e+00 - val_loss: 0.1627\n",
            "Epoch 46/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1838 - val_accuracy: 0.0000e+00 - val_loss: 0.1618\n",
            "Epoch 47/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1898 - val_accuracy: 0.0000e+00 - val_loss: 0.1616\n",
            "Epoch 48/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1854 - val_accuracy: 0.0000e+00 - val_loss: 0.1617\n",
            "Epoch 49/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.2002 - val_accuracy: 0.0000e+00 - val_loss: 0.1643\n",
            "Epoch 50/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1907 - val_accuracy: 0.0000e+00 - val_loss: 0.1622\n",
            "Epoch 51/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1895 - val_accuracy: 0.0000e+00 - val_loss: 0.1620\n",
            "Epoch 52/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1880 - val_accuracy: 0.0000e+00 - val_loss: 0.1648\n",
            "Epoch 53/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1987 - val_accuracy: 0.0000e+00 - val_loss: 0.1615\n",
            "Epoch 54/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1922 - val_accuracy: 0.0000e+00 - val_loss: 0.1625\n",
            "Epoch 55/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1862 - val_accuracy: 0.0000e+00 - val_loss: 0.1658\n",
            "Epoch 56/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1812 - val_accuracy: 0.0000e+00 - val_loss: 0.1632\n",
            "Epoch 57/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1897 - val_accuracy: 0.0000e+00 - val_loss: 0.1620\n",
            "Epoch 58/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1858 - val_accuracy: 0.0000e+00 - val_loss: 0.1611\n",
            "Epoch 59/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1860 - val_accuracy: 0.0000e+00 - val_loss: 0.1631\n",
            "Epoch 60/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.1927 - val_accuracy: 0.0000e+00 - val_loss: 0.1620\n",
            "Epoch 61/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1884 - val_accuracy: 0.0000e+00 - val_loss: 0.1620\n",
            "Epoch 62/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1915 - val_accuracy: 0.0000e+00 - val_loss: 0.1645\n",
            "Epoch 63/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1894 - val_accuracy: 0.0000e+00 - val_loss: 0.1634\n",
            "Epoch 64/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1830 - val_accuracy: 0.0000e+00 - val_loss: 0.1638\n",
            "Epoch 65/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1881 - val_accuracy: 0.0000e+00 - val_loss: 0.1617\n",
            "Epoch 66/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1888 - val_accuracy: 0.0000e+00 - val_loss: 0.1625\n",
            "Epoch 67/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1854 - val_accuracy: 0.0000e+00 - val_loss: 0.1625\n",
            "Epoch 68/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1849 - val_accuracy: 0.0000e+00 - val_loss: 0.1693\n",
            "Epoch 69/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1829 - val_accuracy: 0.0000e+00 - val_loss: 0.1622\n",
            "Epoch 70/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1977 - val_accuracy: 0.0000e+00 - val_loss: 0.1625\n",
            "Epoch 71/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1848 - val_accuracy: 0.0000e+00 - val_loss: 0.1610\n",
            "Epoch 72/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1823 - val_accuracy: 0.0000e+00 - val_loss: 0.1626\n",
            "Epoch 73/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1784 - val_accuracy: 0.0000e+00 - val_loss: 0.1615\n",
            "Epoch 74/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1861 - val_accuracy: 0.0000e+00 - val_loss: 0.1626\n",
            "Epoch 75/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1966 - val_accuracy: 0.0000e+00 - val_loss: 0.1627\n",
            "Epoch 76/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1818 - val_accuracy: 0.0000e+00 - val_loss: 0.1616\n",
            "Epoch 77/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.2002 - val_accuracy: 0.0000e+00 - val_loss: 0.1619\n",
            "Epoch 78/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1827 - val_accuracy: 0.0000e+00 - val_loss: 0.1631\n",
            "Epoch 79/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1863 - val_accuracy: 0.0000e+00 - val_loss: 0.1630\n",
            "Epoch 80/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1870 - val_accuracy: 0.0000e+00 - val_loss: 0.1660\n",
            "Epoch 81/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1893 - val_accuracy: 0.0000e+00 - val_loss: 0.1612\n",
            "Epoch 82/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1893 - val_accuracy: 0.0000e+00 - val_loss: 0.1618\n",
            "Epoch 83/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1880 - val_accuracy: 0.0000e+00 - val_loss: 0.1601\n",
            "Epoch 84/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1871 - val_accuracy: 0.0000e+00 - val_loss: 0.1612\n",
            "Epoch 85/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1873 - val_accuracy: 0.0000e+00 - val_loss: 0.1655\n",
            "Epoch 86/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1863 - val_accuracy: 0.0000e+00 - val_loss: 0.1627\n",
            "Epoch 87/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1884 - val_accuracy: 0.0000e+00 - val_loss: 0.1615\n",
            "Epoch 88/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1845 - val_accuracy: 0.0000e+00 - val_loss: 0.1622\n",
            "Epoch 89/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1917 - val_accuracy: 0.0000e+00 - val_loss: 0.1618\n",
            "Epoch 90/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1942 - val_accuracy: 0.0000e+00 - val_loss: 0.1617\n",
            "Epoch 91/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1972 - val_accuracy: 0.0000e+00 - val_loss: 0.1631\n",
            "Epoch 92/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1783 - val_accuracy: 0.0000e+00 - val_loss: 0.1625\n",
            "Epoch 93/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1895 - val_accuracy: 0.0000e+00 - val_loss: 0.1610\n",
            "Epoch 94/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1851 - val_accuracy: 0.0000e+00 - val_loss: 0.1644\n",
            "Epoch 95/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1888 - val_accuracy: 0.0000e+00 - val_loss: 0.1617\n",
            "Epoch 96/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1822 - val_accuracy: 0.0000e+00 - val_loss: 0.1628\n",
            "Epoch 97/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1899 - val_accuracy: 0.0000e+00 - val_loss: 0.1618\n",
            "Epoch 98/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1877 - val_accuracy: 0.0000e+00 - val_loss: 0.1638\n",
            "Epoch 99/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1983 - val_accuracy: 0.0000e+00 - val_loss: 0.1626\n",
            "Epoch 100/100\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1886 - val_accuracy: 0.0000e+00 - val_loss: 0.1619\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d4bdc18cdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2 = model2.predict(x_test2)\n",
        "print(len(predictions2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln29BQBjoOAF",
        "outputId": "42e4c483-86ea-433b-f56d-a2fab926b917"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "1612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric=0.3 #is the accuracy better than 30%?\n",
        "goodfit2=np.where(((1-metric) < predictions2/y_test2) & ((1+metric) > predictions2/y_test2))\n",
        "badfit2=np.where(((1-metric) > predictions2/y_test2) | ((1+metric) < predictions2/y_test2))\n",
        "\n",
        "print ('With ', neurons_per_layer, 'neurons per layer, ', layers, 'layers, and ', iterations, 'iterations')\n",
        "print ('using the training set', trainbin2)\n",
        "print (len(goodfit2[0])/len(y_test2)*100, 'percent of the ages are good')\n",
        "print (len(badfit2[0])/len(y_test2)*100, 'percent of the ages are bad')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rxyan9eoGvM",
        "outputId": "729e3b7c-3a6d-4c9f-cc4f-919715136e18"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With  20 neurons per layer,  3 layers, and  100 iterations\n",
            "using the training set slice(0, -1614, None)\n",
            "59.86352357320099 percent of the ages are good\n",
            "40.13647642679901 percent of the ages are bad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DR19x2 = np.dstack([data_masked['teff'],data_masked['logg'], data_masked['m_h_atm'],\n",
        "                   data_masked['alpha_m_atm'], data_masked['c_h'], data_masked['n_h']])[0]\n",
        "print(len(data_masked['teff']))\n",
        "\n",
        "DR19x2= DR19x2/scaling_x2\n",
        "tesspredictionsDR19 = model2.predict(DR19x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkeHlcuZoF0H",
        "outputId": "fe333aa9-278e-40f4-af5a-29471213e703"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "963539\n",
            "\u001b[1m30111/30111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(predictionsDR19)\n",
        "total_sum = np.sum(np.nansum(inner_list) for inner_list in predictionsDR19)\n",
        "#print(total_sum)\n",
        "average=total_sum/len(predictionsDR19)\n",
        "print(\"Pinsonneault Average Age in Gyr: \"+str(average))\n",
        "total_sum2 = np.sum(np.nansum(inner_list) for inner_list in tesspredictionsDR19)\n",
        "#print(total_sum2)\n",
        "tessaverage=total_sum2/len(tesspredictionsDR19)\n",
        "print(\"Theodoridis Average Age in Gyr: \"+str(tessaverage))\n",
        "Regtessdiffavg=average-tessaverage\n",
        "print(\"On average, Pinsonneault predicts an age \"+str(Regtessdiffavg)+\" Gyr older than Theodoridis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp0N_Eyen_6R",
        "outputId": "27126ec5-390d-477e-bbc9-65b4dc01225f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-343462506.py:2: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  total_sum = np.sum(np.nansum(inner_list) for inner_list in predictionsDR19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinsonneault Average Age in Gyr: 1.3996949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-343462506.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  total_sum2 = np.sum(np.nansum(inner_list) for inner_list in tesspredictionsDR19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theodoridis Average Age in Gyr: 1.0142978\n",
            "On average, Pinsonneault predicts an age 0.38539708 Gyr older than Theodoridis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nmjIjsx3n1OR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "initial_data = {}\n",
        "initial_df = pd.DataFrame(initial_data)\n",
        "initial_df.to_csv('data.csv', index=False)\n",
        "initial_df['TIC'] = data_masked['tic_v8_id']\n",
        "initial_df['Ages Predicted from Pinsonneault et al. 2025 (Gyr)'] = predictionsDR19\n",
        "initial_df['Ages Predicted from Theodorodis et al. 2025 (Gyr)'] = tesspredictionsDR19\n",
        "initial_df.to_csv('TESS_vs_APOKASC3.csv', index=False)"
      ]
    }
  ]
}